<!--
@license
Copyright 2015 Google Inc. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
<link rel="import" href="../../bower_components/paper-icon-button/paper-icon-button.html">
<link rel="import" href="../../bower_components/paper-fab/paper-fab.html">
<link rel="import" href="../../bower_components/iron-icons/iron-icons.html">
<link rel="import" href="../../bower_components/iron-icons/image-icons.html">
<script src="qrclient.js"></script>

<dom-module id="qr-code">
  <style>
    * {
      user-select: none;
    }
    video {
      display: none;
    }
    #qr-overlay {
      transition: all 300ms ease-in-out;
      position: absolute;
      top: 0;
      left: 0;
      bottom: 0;
      right: 0;
      background-color: transparent;
      border-style: solid;
      border-color: rgba(0, 0, 0, 0.5);
      pointer-events: none;
      z-index: 20;
    }

    #qr-overlay:before {
      content:'';
      top: 0;
      left: 0;
      position: absolute;
      border-top: solid rgba(255,255,255, 0.7) 2px;
      border-left: solid rgba(255,255,255, 0.7) 2px;
      width: 10%;
      height: 10%;
    }

    #qr-overlay:after {
      content:'';
      right: 0;
      bottom: 0;
      position: absolute;
      border-bottom: solid rgba(255,255,255, 0.7) 2px;
      border-right: solid rgba(255,255,255, 0.7) 2px;
      width: 10%;
      height: 10%;
    }
    .Camera--facing-user .Camera-display {
      transform: scale(-1, 1);
    }

    .Camera--facing-environment {
    }

    .Camera-toggle {
      position: absolute;
      margin: 1em;
      bottom: 0;
      right: 0;
      background-color: #0288D1;
      z-index: 50;
    }

    .Camera-toggle-input {
      display: inline-block;
      position: absolute;
      right: 10px;
      bottom: 10px;
    }

    .Camera-instructions {
      position: absolute;
      bottom: 0;
      background-color: #323232;
      font-family: 'Roboto', 'Helvetica', 'Arial', sans-serif;
      color: white;
      padding: 18px;
      border-radius: 2px;
      margin: 1em;
    }

  </style>
  <template>
    <div id="camera" class="Camera">
      <video id="qr-video" class="Camera-video"></video>
      <div id="qr-overlay" class="Camera-overlay"></div>
      <canvas id="qr-canvas" class="Camera-display"></canvas>
      <div class="Camera-instructions">Point at a QR code</div>
      <div class="Camera-toggle">
        <template is="dom-if" if="{{toggleSwitch}}">
          <paper-fab on-tap="toggleCamera" icon="{{_getCameraIcon(_frontCamera)}}" class="Camera-toggle-input"></paper-fab>
        </template>
      </div>
    </div>
  </template>
</dom-module>

<script>
var requestAnimationFrame = (function() {
  'use strict';
  return window.requestAnimationFrame ||
    window.webkitRequestAnimationFrame ||
    window.mozRequestAnimationFrame ||
    function(callback) {
      window.setTimeout(callback, 1000 / 60);
    };
})();

// A shim for getUserMedia method on the mediaDevices object.
if (!navigator.mediaDevices.getUserMedia) {
  navigator.mediaDevices.getUserMedia = function(constraints) {
    return new Promise(function(resolve, reject) {
      navigator.webkitGetUserMedia(constraints, resolve, reject);
    });
  };
}

let CameraManager = function(that) {
  // The camera gets a video stream, and adds it to a canvas.
  // The canvas is analysed but also displayed to the user.
  // The video is never show

  let self = this;

  let cameraRoot = that.$.camera;
  let cameraVideo = that.$['qr-video'];
  let cameraCanvas = that.$['qr-canvas'];
  let cameraOverlay = that.$['qr-overlay'];

  let canvas = cameraCanvas.getContext('2d');

  // Variables
  let dWidth, dHeight, dx = 0, dy = 0;
  let sx = 0, sy = 0, sHeight, sWidth, scaleX, scaleY, scaleFactor = 1;

  let coordinatesHaveChanged = false;
  let prevCoordinates = 0;
  // The camera stream.
  this.localStream;

  let overlayCoords = {
    x: 0,
    y: 0,
    width: cameraCanvas.width,
    height: cameraCanvas.height
  };

  this.getImageData = function() {
    // Only get the image data for what we will send to the detector.
    return canvas.getImageData(
      overlayCoords.x,
      overlayCoords.y,
      overlayCoords.width,
      overlayCoords.height
    );
  };

  let drawOverlay = (width, height) => {

    let minLength = Math.min(width, height);

    let boxHeightSize = (height + 64 - minLength) / 2;
    let boxWidthSize = (width + 64 - minLength) / 2;

    if (coordinatesHaveChanged) {
      cameraOverlay.style.borderTopWidth = boxHeightSize + "px";
      cameraOverlay.style.borderLeftWidth = boxWidthSize + "px";
      cameraOverlay.style.borderRightWidth = boxWidthSize + "px";
      cameraOverlay.style.borderBottomWidth = boxHeightSize + "px";

      overlayCoords.x = boxWidthSize;
      overlayCoords.y = boxHeightSize
      overlayCoords.width = cameraCanvas.width - (boxWidthSize * 2);
      overlayCoords.height = cameraCanvas.height - (boxHeightSize * 2);
    }
  };

  let setupVariables = e => {
    dWidth = cameraCanvas.width = window.innerWidth;
    dHeight = cameraCanvas.height = window.innerHeight;
    dx = 0;
    dy = 0;

    sx = 0;
    sy = 0;

    // Make the video coordinate space the same as the window.
    // size in the longest dimension.
    // Then center and clip. and map back to correct space.
    scaleX = (dWidth / cameraVideo.videoWidth);
    scaleY = (dHeight / cameraVideo.videoHeight);
    scaleFactor = Math.max(scaleX, scaleY);

    // Trim the left
    sx = ((cameraVideo.videoWidth * scaleFactor) / 2) - (dWidth/ 2);
    sy = ((cameraVideo.videoHeight * scaleFactor) / 2) - (dHeight / 2);

    // Trim the right.
    sWidth = (cameraVideo.videoWidth * scaleFactor) - sx * 2;
    sHeight = (cameraVideo.videoHeight * scaleFactor) - sy * 2;

    return (cameraVideo.videoWidth > 0);
  };

  let captureFrame = () => {
    // Work out which part of the video to capture and apply to canvas.
    canvas.drawImage(
      cameraVideo,
      sx /scaleFactor,
      sy/scaleFactor,
      sWidth/scaleFactor,
      sHeight/scaleFactor,
      dx,
      dy,
      dWidth,
      dHeight
    );

    drawOverlay(dWidth, dHeight, scaleFactor);

    // A frame has been captured.
    if (self.onframe) self.onframe();

    coordinatesHaveChanged = false;

    requestAnimationFrame(captureFrame.bind(self));
  };

  this.getCamera = videoSource => {
    // let params;
    //
    // if (videoSource === undefined && that.cameras.length == 0) {
    //   // Because we have no source information, have to assume it user facing.
    //   params = { video: true };
    // } else {
    //   // params = { video: { deviceId: videoSource.deviceId } };
    //   params = { video: { facingMode: { exact: 'environment' } } };
    // }
    //
    // return navigator.mediaDevices.getUserMedia(params)
    // .then(theStream => {
    let gUM = (navigator.getUserMedia ||
               navigator.webkitGetUserMedia ||
               navigator.mozGetUserMedia ||
               navigator.msGetUserMedia || null);

    gUM = constraints => new Promise((resolve, reject) => {
      gUM(constraints, resolve, reject);
    });

    let params;

    if (videoSource === undefined && that.cameras.length == 0) {
      // Because we have no source information, have to assume it user facing.
      params = { video: true };
    } else {
      params = { video: { optional: [ { sourceId: videoSource.id } ] } };
    }

    return gUM.call(navigator, params).then(theStream => {

      self.localStream = theStream;

      cameraVideo.onloadeddata = function(e) {

        coordinatesHaveChanged = true;

        var isSetup = setupVariables(e);
        if (isSetup) {
          requestAnimationFrame(captureFrame.bind(self));
        } else {
          // This is just to get around the fact that the videoWidth is not
          // available in Firefox until sometime after the data has loaded.
          setTimeout(function() {
            setupVariables(e);
            requestAnimationFrame(captureFrame.bind(self));
          }, 1000);
        }

        // // The video is ready, and the camerea captured
        // if (videoSource === undefined) {
        //   // There is no meta data about the camera, assume user facing.
        //   videoSource = {
        //     'facing': 'user'
        //   };
        // }

        // var facing = videoSource.facing ? videoSource.facing : 'user';
        let facing = /front/.test(videoSource.label) ? 'user' : 'environment';
        cameraRoot.classList.remove('Camera--facing-environment');
        cameraRoot.classList.remove('Camera--facing-user');
        cameraRoot.classList.add('Camera--facing-' + facing);
      };

      cameraVideo.src = window.URL.createObjectURL(self.localStream);
      cameraVideo.load();
      cameraVideo.play();
    }, error => {
      console.error(error);
    });
  };

  window.addEventListener('resize', () => {
    coordinatesHaveChanged = true;
    setupVariables();
  });
};

class QrCode {
  get is() {
    return 'qr-code';
  }

  get properties() {
    return {
      _camera: {
        type: Object,
        value: {}
      },
      toggleSwitch: {
        type: Boolean,
        value: false
      },
      cameras: {
        type: Array,
        value: []
      },
      _frontCamera: {
        type: Boolean,
        value: true,
        observer: '_onChangeCamera'
      },
      active: {
        type: Boolean,
        value: false,
        observer: '_onActiveChanged'
      }
    }
  }

  get listeners() {
    return {
      'visibilitychange': 'onVisibilityChange'
    }
  }

  ready() {
    this.cameraManager = new CameraManager(this);
    this.client        = new QRClient();
    this.processingFrame = false;

    this.cameraManager.onframe = () => {
      // There is a frame in the camera, what should we do with it?
      if (this.processingFrame == false) {
        this.processingFrame = true;
        let imageData = this.cameraManager.getImageData();
        this.client.decode(imageData, result => {
          if (result !== undefined) {
            this.fire('qrcode-detected', {code: result});
          }
          this.processingFrame = false;
        });
      }
    };
    //
    // if ('mediaDevices' in navigator) {
    //   navigator.mediaDevices.enumerateDevices().then(devices => {
    //     for (let device of devices) {
    //       if (device.kind === 'videoinput') {
    //         if (/back/.test(device.label)) {
    //           this.cameras.unshift(device);
    //         } else {
    //           this.cameras.push(device);
    //         }
    //       }
    //     }
    //
    //     if (this.cameras.length > 1) {
    //       this.toggleSwitch = true;
    //     }
    //   });
    // }

    if ('getSources' in MediaStreamTrack) {
      MediaStreamTrack.getSources(sources => {
        for (let source of sources) {
          if (source.kind === 'video') {
            if (source.facing === 'environment') {
              // cameras facing the environment are pushed to the front of the page
              this.cameras.unshift(source);
            } else {
              this.cameras.push(source);
            }
          }
        }
        if (this.cameras.length > 1) {
          this.toggleSwitch = true;
        }
      });
    }

    document.addEventListener('visibilitychange', this.onVisibilityChange.bind(this));
  }

  _getCameraIcon(frontCamera) {
    return frontCamera ? 'image:camera-front' : 'image:camera-rear';
  }

  toggleCamera(e) {
    this._frontCamera = !this._frontCamera;
  }

  _onChangeCamera() {
    if (this.cameraManager) {
      if (this.cameraManager.localStream !== undefined) {
        this.cameraManager.localStream.getTracks()[0].stop();
        this.cameraManager.localStream = undefined;
      }
      this.cameraManager.getCamera(this.cameras[this._frontCamera ? 0 : 1]);
    }
  }

  _onActiveChanged() {
    if (this.cameraManager) {
      if (this.active) {
        if (this.cameras.length > 1) {
          var cameraIdx = this._frontCamera ? 0 : 1;
        } else {
          var cameraIdx = 0;
        }
        this.cameraManager.getCamera(this.cameras[cameraIdx]);
      } else if (this.cameraManager.localStream !== undefined) {
        this.cameraManager.localStream.getTracks()[0].stop();
        this.cameraManager.localStream = undefined;
      }
    }
  }

  onVisibilityChange(e) {
    if (!this.active) return;
    if (document.visibilityState === 'hidden') {
      // Disconnect the camera.
      if (this.cameraManager.localStream !== undefined) {
        this.cameraManager.localStream.getTracks()[0].stop();
        this.cameraManager.localStream = undefined;
      }
    } else {
      this._onChangeCamera();
    }
  }
};

Polymer(QrCode.prototype);
</script>
